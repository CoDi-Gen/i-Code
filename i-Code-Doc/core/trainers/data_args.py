from dataclasses import dataclass, field
from typing import Optional


@dataclass
class UDOPDataTrainingArguments:
    """Arguments pertaining to what data we are going to input our model for
    training and eval."""

    data_dir:Optional[str] = field(default=None)
    dataset_name: Optional[str] = field(
        default=None,
        metadata={
            'help':
            'The name of the dataset to use (via the datasets library).'
        })
    dataset_config_name: Optional[str] = field(
        default=None,
        metadata={
            'help':
            'The configuration name of the dataset to use (via the datasets library).'
        })
    train_file: Optional[str] = field(
        default=None,
        metadata={
            'help': 'The input training data file (a csv or JSON file).'
        })
    validation_file: Optional[str] = field(
        default=None,
        metadata={
            'help':
            'An optional input evaluation data file to evaluate on (a csv or JSON file).'
        },
    )
    test_file: Optional[str] = field(
        default=None,
        metadata={
            'help':
            'An optional input test data file to predict on (a csv or JSON file).'
        },
    )
    overwrite_cache: bool = field(
        default=False,
        metadata={'help': 'Overwrite the cached training and evaluation sets'})
    preprocessing_num_workers: Optional[int] = field(
        default=None,
        metadata={
            'help': 'The number of processes to use for the preprocessing.'
        },
    )
    pad_to_max_length: bool = field(
        default=False,
        metadata={
            'help':
            'Whether to pad all samples to model maximum sentence length. '
            'If False, will pad the samples dynamically when batching to the maximum length in the batch. More '
            'efficient on GPU but very bad for TPU.'
        },
    )
    label_all_tokens: bool = field(
        default=False,
        metadata={
            'help':
            'Whether to put the label for one word on all tokens of generated by that word or just on the '
            'one (in which case the other tokens will have a padding index).'
        },
    )
    add_prefix_space: bool = field(
        default=True,
        metadata={
            'help': 'For Longformer only. Otherwise there\'s error: You need to instantiate RobertaTokenizerFast '
            'with add_prefix_space=True to use it with pretokenized inputs'
        },
    )
    max_seq_length: int = field(
        default=512,
        metadata={
            'help':
            'The maximum total input sequence length after tokenization. Sequences longer '
            'than this will be truncated, sequences shorter will be padded.'
        },
    max_seq_length_decoder: int = field(
        default=256,
        metadata={
            'help':
            'The maximum total input sequence length after tokenization. Sequences longer '
            'than this will be truncated, sequences shorter will be padded.'
        },
    )
    do_supervised: bool = field(
        default=False,
        metadata={
            'help': 'do supervised tasks'
        },
    )
    do_selfsupervised: bool = field(
        default=True,
        metadata={
            'help': 'do self supervised tasks'
        },
    )
        publaynet_dir: str = field(
        default=None,
        metadata={
            'help': 'publaynet directory'
        },
    )
        
    websrc_dir: str = field(
        default=None,
        metadata={
            'help': 'websrc directory'
        },
    )

    docbank_dir: str = field(
        default=None,
        metadata={
            'help': 'docbank directory'
        },
    )

    rvlcdip_dir: str = field(
        default=None,
        metadata={
            'help': 'rvlcdip directory'
        },
    )

    mpdfs_dir: str = field(
        default=None,
        metadata={
            'help': 'mpdfs directory'
        },
    )
